# -*- coding: utf-8 -*-
"""Tugas_Deteksi_ASD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1plE0Vh--Ry5TwuHPsB91xefWQ9jdKkPM
"""

import sys
import pandas as pd
import sklearn
from tensorflow import keras

print('Python: {}'.format(sys.version))
print('Pandas: {}'.format(pd.__version__))
print('Sklearn: {}'.format(sklearn.__version__))
print('Keras (from TensorFlow): {}'.format(keras.__version__))

# Mount Google Drive ke Google Colaboratory
from google.colab import drive
drive.mount('/content/drive')

# import dataset dari google drive
file = '/content/drive/My Drive/SEMESTER 6/ADK/Tugas Besar/Autism-Child-Data.txt'

# Daftar nama kolom
columns = [
    'A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10',
    'age', 'gender', 'ethnicity', 'jaundice', 'family_history',
    'country_of_residence', 'used_app_before', 'screening_score',
    'age_desc', 'relation', 'class'
]
# Dataset dibaca dari file .txt dengan pemisah koma (,), dan diberi nama kolom manual
data = pd.read_table(file, sep = ',', index_col = None, names=columns)

data

# Print shape of the DataFrame, agar kita bisa lihat berapa banyak data yang ada dalam dataset
print('Shape of DataFrame: {}'.format(data.shape))
print(data.loc[0])

# print data untuk 11 pertama pasien
print(data.loc[:10])

#print data t#print data yang mana dapat membantu kita untuk mengolah dataset
data.describe()

# cek kolom mana yang berisi kategorikal (object)
data.dtypes

import numpy as np
data.replace("?", np.nan, inplace=True) # mengganti value "?" menjadi NaN
# drop kolom yang tidak dibutuhkan
data = data.drop(['screening_score', 'age_desc'], axis=1)
print(data.isna().sum())  # Melihat jumlah nilai NaN per kolom

# Bagi dataset menjadi 2 bagian x dan y . x adaklah attribute yang kita gunakan untuk prediksi dan y adalah yang menjadi class atau label
x = data.drop(['class'], axis=1)
y = data['class']

# print out x dan kolom class sudah terhapus
x

# Membagi data: 80% untuk latih, 20% untuk uji
# random_state=42 agar hasil pembagian selalu sama jika dijalankan ulang
# stratify=y agar proporsi kelas YES/NO di data latih & uji sama (penting!)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
print("\nUkuran data setelah di-split:")
print("X_train:", X_train.shape)
print("X_test:", X_test.shape)
print("y_train:", y_train.shape)
print("y_test:", y_test.shape)

#Gabungkan X_train dan X_test Ini penting agar kategori di data latih dan uji di-encode dengan cara yang sama.
X_combined = pd.concat([X_train, X_test], axis=0)

X_encoded = pd.get_dummies(X_combined, drop_first=True)

# Split kembali setelah encoding
X_train_encoded = X_encoded.iloc[:len(X_train)]
X_test_encoded = X_encoded.iloc[len(X_train):]

print(f"\nShape setelah OHE:")
print(f"X_train_encoded: {X_train_encoded.shape}")
print(f"X_test_encoded: {X_test_encoded.shape}")
print(f"\nJumlah fitur bertambah dari {X_train.shape[1]} menjadi {X_train_encoded.shape[1]}")

#  Jika ada nilai kosong setelah encoding, diisi dengan nilai yang paling sering muncul di kolom tersebut (most_frequent)
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy='most_frequent')
X_train_encoded = pd.DataFrame(imputer.fit_transform(X_train_encoded),
                              columns=X_train_encoded.columns,
                              index=X_train_encoded.index)
X_test_encoded = pd.DataFrame(imputer.transform(X_test_encoded),
                             columns=X_test_encoded.columns,
                             index=X_test_encoded.index)

print("\nContoh fitur setelah OHE:")
print(X_train_encoded.columns.tolist()[:20])  # Tampilkan 20 fitur pertama

X_train_encoded #cek hasil OHE

X_train_encoded.loc[1]

